    // ---------------------------------------------------------------------------------
    // Run (pełny)
    // ---------------------------------------------------------------------------------
    async fn run(&self, files: Vec<FileProcess>) -> Result<()> {
        let mut process_exec_id: Option<i64> = None;

        // DB init
        if let Some(db) = &self.db {
            let process_cd = &self.cfg.process_cd.clone().unwrap_or("UNKNOWN".into());
            let file_watcher_id = self.cfg.file_watcher_id.unwrap_or(0);
            let tech_insert_id = self.cfg.tech_insert_id.unwrap_or(0);
            info!(
                %process_cd,
                %file_watcher_id,
                %tech_insert_id,
                "Wywołuję start_process_f()"
            );
            let pid = db
                .init_session(process_cd, file_watcher_id, tech_insert_id)
                .await?;
            info!(%pid, "Sesja procesu zainicjalizowana w DB");
            process_exec_id = Some(pid);
        } else {
            warn!("Brak połączenia z DB – pomijam start_process_f");
        }

        info!("Rozpoczynam przetwarzanie plików...");

        // globalny znacznik błędu dla trybów ASYNC
        let error_flag = Arc::new(AtomicBool::new(false));

        match (self.cfg.workflow_type, self.cfg.dispatch_mode) {
            (WorkflowType::Static, DispatchMode::Batch) => {
                self.run_static_wfl_batch_jobs(&files).await?
            }
            (WorkflowType::Static, DispatchMode::Async) => {
                self.run_static_wfl_async_jobs(files, error_flag.clone()).await?
            }
            (WorkflowType::Dynamic, DispatchMode::Batch) => {
                self.run_dynamic_wfl_batch_jobs(files).await?
            }
            (WorkflowType::Dynamic, DispatchMode::Async) => {
                self.run_dynamic_wfl_async_jobs(files, error_flag.clone()).await?
            }
        }

        // zapis końcowego statusu procesu
        if let (Some(db), Some(pid)) = (&self.db, process_exec_id) {
            let any_error = error_flag.load(Ordering::SeqCst);
            let (status_cd, error_msg) = if any_error {
                ("ERROR", "One or more files failed")
            } else {
                ("COMPLETED", "")
            };

            let tech_update_id = self
                .cfg
                .tech_update_id
                .or(self.cfg.tech_insert_id)
                .unwrap_or(0);

            if let Err(e) = db
                .end_session(pid, status_cd, error_msg, tech_update_id)
                .await
            {
                error!(error = ?e, "Błąd końcowego zapisu finish_process_f do DB");
            }
        } else {
            warn!("Brak połączenia z DB lub brak process_exec_id – pomijam end_session");
        }

        Ok(())
    }


=====


    // ---------------------------------------------------------------------------------
    // STATIC + ASYNC
    // ---------------------------------------------------------------------------------
    async fn run_static_wfl_async_jobs(
        &self,
        files: Vec<FileProcess>,
        error_flag: Arc<AtomicBool>,
    ) -> Result<()> {
        let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
        let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

        let remaining_files = Arc::new(AtomicUsize::new(files.len()));
        let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());

        // 1. pierwszy krok dla każdego pliku
        for f in &files {
            if f.processes.is_empty() {
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                continue;
            }

            let mut steps = f.processes.clone();
            steps.sort_by_key(|s| s.exec_process_seq);

            let first_step = steps.remove(0);
            steps_cache.insert(f.file_id.clone(), steps.into());

            tx_tasks.send(FileTask {
                file_id: f.file_id.clone(),
                gcs_file_uri: f.gcs_file_uri.clone(),
                step: first_step,
            })?;
        }

        drop(files);

        // 2. Poller
        let rx_exec_for_poller = rx_exec.clone();
        let dispatcher_for_poller = self.clone_light();
        let error_flag_for_poller = error_flag.clone();

        let poller_handle = tokio::spawn(async move {
            loop {
                let maybe_id = tokio::task::spawn_blocking({
                    let rx = rx_exec_for_poller.clone();
                    move || rx.recv()
                })
                .await;

                let exec_id = match maybe_id {
                    Ok(Ok(id)) => id,
                    Ok(Err(_)) => {
                        info!("STATIC+ASYNC poller: kanał exec_id zamknięty — kończę");
                        break;
                    }
                    Err(e) => {
                        error!(?e, "STATIC+ASYNC poller: JoinError");
                        error_flag_for_poller.store(true, Ordering::SeqCst);
                        break;
                    }
                };

                if let Some(cr) = dispatcher_for_poller
                    .backend
                    .as_any()
                    .downcast_ref::<CloudRunBackend>()
                {
                    if let Err(e) = cr
                        .poll_until_done(
                            &exec_id,
                            Duration::from_secs(1800),
                            Duration::from_secs(10),
                        )
                        .await
                    {
                        error!(error=?e, %exec_id, "STATIC+ASYNC poller: błąd poll");
                        error_flag_for_poller.store(true, Ordering::SeqCst);
                    }
                }
            }
        });

        // 3. Worker pool
        let workers = self.cfg.max_workers;
        let mut worker_handles = Vec::new();

        for _ in 0..workers {
            let rx_tasks_clone = rx_tasks.clone();
            let tx_tasks_clone = tx_tasks.clone();
            let tx_exec_clone = tx_exec.clone();
            let dispatcher = self.clone_light();
            let remaining_files = Arc::clone(&remaining_files);
            let steps_cache = Arc::clone(&steps_cache);
            let error_flag = error_flag.clone();

            let h = std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new()
                    .expect("Tokio Runtime worker error");

                loop {
                    // jeśli już nie ma żadnych plików do obsługi – kończymy worker
                    if remaining_files.load(Ordering::Acquire) == 0 {
                        break;
                    }

                    match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
                        Ok(task) => {
                            let dispatcher_c = dispatcher.clone_light();

                            let res = rt.block_on(async {
                                dispatcher_c
                                    .process_static_task(
                                        task,
                                        &tx_tasks_clone,
                                        &remaining_files,
                                        &steps_cache,
                                        &tx_exec_clone,
                                        &error_flag,
                                    )
                                    .await
                            });

                            if let Err(e) = res {
                                // UWAGA: tutaj TYLKO logujemy.
                                // remaining_files i error_flag są obsługiwane w process_static_task.
                                error!(error = ?e, "STATIC+ASYNC worker error");
                            }
                        }
                        Err(RecvTimeoutError::Timeout) => {
                            continue;
                        }
                        Err(RecvTimeoutError::Disconnected) => {
                            break;
                        }
                    }
                }
            });

            worker_handles.push(h);
        }

        drop(tx_tasks);

        for h in worker_handles {
            let _ = h.join();
        }

        drop(tx_exec);

        let _ = poller_handle.await;

        info!(
            remaining = remaining_files.load(Ordering::Acquire),
            "STATIC+ASYNC zakończone"
        );
        Ok(())
    }


===


    async fn process_static_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        tx_exec: &Sender<String>,
        error_flag: &Arc<AtomicBool>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. ENV vars per step
        let mut envs = self.cfg.env_vars.clone();
        let tgt_path = step
            .params
            .get("trg_path")
            .and_then(|v| v.as_str())
            .unwrap_or("");

        envs.insert("TGT_PATH".into(), tgt_path.to_string());

        let payload = serde_json::json!({
            "process_id": self.cfg.process_id,
            "dispatcher_run_id": self.dispatcher_run_id.to_string(),
            "file_id": file_id,
            "gcs_file_uri": gcs_file_uri,
            "process_cd": step.process_cd,
            "seq": step.exec_process_seq,
        });

        let job_name = &step.exec_object_nm;

        // 2. start_job / dispatch_job
        let exec_id = match self.backend.as_any().downcast_ref::<CloudRunBackend>() {
            Some(cr) => match cr.start_job(job_name, &payload, &envs).await {
                Ok(id) => id,
                Err(e) => {
                    error!(error=?e, %file_id, "STATIC+ASYNC: błąd start_job");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            },
            None => match self.backend.dispatch_job(job_name, &payload).await {
                Ok(id) => id,
                Err(e) => {
                    error!(error=?e, %file_id, "STATIC+ASYNC: błąd dispatch_job");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            },
        };

        info!(
            %exec_id,
            %file_id,
            seq = step.exec_process_seq,
            obj = %step.exec_object_nm,
            "STATIC+ASYNC: job uruchomiony"
        );

        // 3. wysłanie exec_id do pollera
        if let Err(e) = tx_exec.send(exec_id) {
            error!(error=?e, %file_id, "STATIC+ASYNC: błąd wysyłania exec_id do pollera");
            error_flag.store(true, Ordering::SeqCst);
            remaining_files.fetch_sub(1, Ordering::AcqRel);
            return Err(anyhow::anyhow!("STATIC+ASYNC: poller channel closed"));
        }

        // 4. Kolejny krok
        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let new_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(new_task) {
                    error!(error=?e, %file_id, "STATIC+ASYNC: błąd wysyłania next_step");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(anyhow::anyhow!("STATIC+ASYNC: task channel closed"));
                }

                return Ok(()); // kolejny krok wrzucony – plik trwa dalej
            } else {
                drop(entry);
                steps_cache.remove(file_id);
            }
        }

        // 5. Brak kolejnych kroków → koniec pliku
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        Ok(())
    }


====


    // ---------------------------------------------------------------------------------
    // DYNAMIC + ASYNC (independent per file)
    // ---------------------------------------------------------------------------------
    async fn run_dynamic_wfl_async_jobs(
        &self,
        files: Vec<FileProcess>,
        error_flag: Arc<AtomicBool>,
    ) -> Result<()> {
        let db = self
            .db
            .as_ref()
            .cloned()
            .ok_or_else(|| anyhow::anyhow!("Brak połączenia z DB dla dynamicznego workflow"))?;

        let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
        let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

        let remaining_files = Arc::new(AtomicUsize::new(files.len()));
        let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());

        // 1. pierwszy krok per file z payloadu
        for f in &files {
            if let Some(first_step) = f.processes.iter().min_by_key(|s| s.exec_process_seq) {
                let task = FileTask {
                    file_id: f.file_id.clone(),
                    gcs_file_uri: f.gcs_file_uri.clone(),
                    step: first_step.clone(),
                };
                let _ = tx_tasks.send(task);
            } else {
                remaining_files.fetch_sub(1, Ordering::AcqRel);
            }
        }

        drop(files);

        // 2. Poller
        let rx_exec_for_poller = rx_exec.clone();
        let dispatcher_for_poller = self.clone_light();
        let error_flag_for_poller = error_flag.clone();

        let poller_handle = tokio::spawn(async move {
            loop {
                let maybe_id = tokio::task::spawn_blocking({
                    let rx = rx_exec_for_poller.clone();
                    move || rx.recv()
                })
                .await;

                let exec_id = match maybe_id {
                    Ok(Ok(id)) => id,
                    Ok(Err(_)) => break,
                    Err(e) => {
                        error!(?e, "DYNAMIC+ASYNC poller: JoinError");
                        error_flag_for_poller.store(true, Ordering::SeqCst);
                        break;
                    }
                };

                if let Some(cr) = dispatcher_for_poller
                    .backend
                    .as_any()
                    .downcast_ref::<CloudRunBackend>()
                {
                    if let Err(e) = cr
                        .poll_until_done(
                            &exec_id,
                            Duration::from_secs(1800),
                            Duration::from_secs(10),
                        )
                        .await
                    {
                        error!(error=?e, %exec_id, "DYNAMIC+ASYNC poller: błąd poll");
                        error_flag_for_poller.store(true, Ordering::SeqCst);
                    }
                }
            }
        });

        // 3. Workers
        let mut worker_handles = Vec::new();

        for _ in 0..self.cfg.max_workers {
            let rx_tasks_clone = rx_tasks.clone();
            let tx_tasks_clone = tx_tasks.clone();
            let tx_exec_clone = tx_exec.clone();
            let dispatcher = self.clone_light();
            let remaining_files = Arc::clone(&remaining_files);
            let steps_cache = Arc::clone(&steps_cache);
            let db_clone = db.clone();
            let error_flag = error_flag.clone();

            let h = std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new()
                    .expect("Tokio Runtime worker dynamic");

                loop {
                    if remaining_files.load(Ordering::Acquire) == 0 {
                        break;
                    }

                    match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
                        Ok(task) => {
                            let dispatcher_c = dispatcher.clone_light();
                            let db_for_call = db_clone.clone();

                            let res = rt.block_on(async {
                                dispatcher_c
                                    .process_dynamic_task(
                                        task,
                                        &tx_tasks_clone,
                                        &remaining_files,
                                        &steps_cache,
                                        &db_for_call,
                                        &tx_exec_clone,
                                        &error_flag,
                                    )
                                    .await
                            });

                            if let Err(e) = res {
                                // jak wyżej – tylko log
                                error!(error=?e, "DYNAMIC+ASYNC worker error");
                            }
                        }
                        Err(RecvTimeoutError::Timeout) => continue,
                        Err(RecvTimeoutError::Disconnected) => break,
                    }
                }
            });

            worker_handles.push(h);
        }

        drop(tx_tasks);

        for h in worker_handles {
            let _ = h.join();
        }

        drop(tx_exec);

        let _ = poller_handle.await;

        info!(
            remaining = remaining_files.load(Ordering::Acquire),
            "DYNAMIC+ASYNC zakończone"
        );

        Ok(())
    }


====

    async fn process_dynamic_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        db: &Arc<Db>,
        tx_exec: &Sender<String>,
        error_flag: &Arc<AtomicBool>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. ENV VARS per step
        let mut envs = self.cfg.env_vars.clone();
        let tgt_path = step
            .params
            .get("trg_path")
            .and_then(|v| v.as_str())
            .unwrap_or("");
        envs.insert("TGT_PATH".into(), tgt_path.to_string());

        let payload = serde_json::json!({
            "process_id": self.cfg.process_id,
            "dispatcher_run_id": self.dispatcher_run_id.to_string(),
            "file_id": file_id,
            "gcs_file_uri": gcs_file_uri,
            "process_cd": step.process_cd,
            "seq": step.exec_process_seq,
        });

        let job_name = &step.exec_object_nm;

        // 2. start_job / dispatch_job
        let exec_id = match self.backend.as_any().downcast_ref::<CloudRunBackend>() {
            Some(cr) => {
                match cr.start_job(job_name, &payload, &envs).await {
                    Ok(id) => id,
                    Err(e) => {
                        error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd start_job");
                        error_flag.store(true, Ordering::SeqCst);
                        remaining_files.fetch_sub(1, Ordering::AcqRel);
                        return Err(e);
                    }
                }
            }
            None => {
                match self.backend.dispatch_job(job_name, &payload).await {
                    Ok(id) => id,
                    Err(e) => {
                        error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd dispatch_job");
                        error_flag.store(true, Ordering::SeqCst);
                        remaining_files.fetch_sub(1, Ordering::AcqRel);
                        return Err(e);
                    }
                }
            }
        };

        info!(
            %exec_id,
            %file_id,
            seq = step.exec_process_seq,
            obj = %step.exec_object_nm,
            "DYNAMIC+ASYNC: job uruchomiony"
        );

        // 3. wysyłamy exec_id do pollera
        if let Err(e) = tx_exec.send(exec_id) {
            error!(error=?e, %file_id, "DYNAMIC+ASYNC: nie udało się wysłać exec_id do pollera");
            error_flag.store(true, Ordering::SeqCst);
            remaining_files.fetch_sub(1, Ordering::AcqRel);
            return Err(anyhow::anyhow!("Kanał pollera zamknięty"));
        }

        // 4. jeśli brak entry w cache → pobieramy z DB
        if !steps_cache.contains_key(file_id) {
            let steps = match db.get_steps_for_file(file_id).await {
                Ok(s) => s,
                Err(e) => {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd get_steps_for_file");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            };

            if steps.is_empty() {
                let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
                info!(%file_id, prev_remaining=%prev, "DYNAMIC+ASYNC: brak dalszych kroków — koniec pliku");
                return Ok(());
            }

            let mut sorted = steps;
            sorted.sort_by_key(|s| s.exec_process_seq);
            steps_cache.insert(file_id.clone(), sorted.into());
        }

        // 5. enqueue next step
        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let next_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(next_task) {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd wysłania kolejnego kroku");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(anyhow::anyhow!("Kanał workerów zamknięty"));
                }

                return Ok(());
            } else {
                drop(entry);
                steps_cache.remove(file_id);
            }
        }

        // 6. koniec pliku
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        Ok(())
    }


====

