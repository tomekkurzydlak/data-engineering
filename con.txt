Universal Data Repository â€“ Dispatcher Workflow (Dokumentacja)
1. OgÃ³lny opis dziaÅ‚ania Dispatchera
Dispatcher jest komponentem odpowiedzialnym za:
przyjÄ™cie listy plikÃ³w do przetworzenia,
zakolejkowanie ich w pamiÄ™ci,
rozdzielenie pomiÄ™dzy poszczegÃ³lne kroki przetwarzania (tzw. process steps),
wykonywanie odpowiednich jobÃ³w w Cloud Run,
monitorowanie statusÃ³w poprzez polling,
aktualizacjÄ™ statusÃ³w procesu w bazie danych (Cloud SQL / PostgreSQL).
Dispatcher dziaÅ‚a w dwÃ³ch osiach konfiguracyjnych:
Workflow Type
static â€“ peÅ‚na lista krokÃ³w istnieje w payloadzie
dynamic â€“ tylko pierwszy krok jest w payloadzie, kolejne pobierane sÄ… z DB
Dispatch Mode
batch â€“ kroki wykonywane sÄ… sekwencyjnie globalnie (po SEQ), w batchach
async â€“ kaÅ¼dy plik ma wÅ‚asnÄ… sekwencjÄ™ wykonywanÄ… przez worker pool
Te tryby dajÄ… Å‚Ä…cznie 4 modele dziaÅ‚ania.
ğŸŸ¦ 2. WywoÅ‚anie Dispatchera przez Orkiestrator
Orkiestrator okresowo (lub eventowo) uruchamia binarkÄ™ udr-dispatcher, przekazujÄ…c parametry CLI, m.in.:
NajwaÅ¼niejsze parametry:
parametr	opis
--process-id	globalny identyfikator procesu
--gcp-project	GCP Project ID
--pg-dsn	DSN poÅ‚Ä…czenia z Postgres
--payload lub --payload-file	lista plikÃ³w wraz z krokami
--workflow-type	static / dynamic
--dispatch-mode	batch / async
--file-watcher-id	ÅºrÃ³dÅ‚o batcha (dynamic batch)
--tech-insert-id / --tech-update-id	identyfikatory techniczne
--env-vars	globalne zmienne Å›rodowiskowe, przekazywane do Cloud Run
--max-workers	liczba workerÃ³w w trybie async
Orkiestrator uruchamia:
udr-dispatcher \
  --process-id 12345 \
  --gcp-project myproj \
  --pg-dsn postgresql://... \
  --payload-file /path/payload.json \
  --workflow-type static \
  --dispatch-mode async \
  --tech-insert-id 55 \
  --tech-update-id 55
ğŸŸ¦ 3. Inicjalizacja Dispatchera
Po starcie:
Dispatcher parsuje parametry CLI (Cli â†’ AppConfig).
Åaduje payload (lista plikÃ³w).
Tworzy poÅ‚Ä…czenie do DB (chyba Å¼e --dry-run).
WywoÅ‚uje procedurÄ™ w bazie:
select start_process_f(process_cd, file_watcher_id, tech_insert_id)
otrzymujÄ…c process_exec_id, czyli identyfikator sesji procesu.
Dopiero wtedy przechodzi do wykonania logiki w zaleÅ¼noÅ›ci od trybu workflow i dispatch.
ğŸŸ¦ 4. Tryby dziaÅ‚ania â€“ szczegÃ³Å‚owy opis
4.1. STATIC + BATCH
PeÅ‚na lista krokÃ³w dla kaÅ¼dego pliku pochodzi z payloadu.
Kroki sÄ… grupowane wedÅ‚ug exec_process_seq.
Dispatcher wykonuje SEQ po SEQ, kaÅ¼dy jako batch.
KaÅ¼dy batch jest grupowany per image (exec_object_nm), a nastÄ™pnie wysyÅ‚any do Cloud Run:
start_job(batch_payload)
poll_until_done(exec_id)
NastÄ™pny SEQ jest wykonywany dopiero po zakoÅ„czeniu poprzedniego.
Zero zapytaÅ„ do DB podczas przetwarzania.
4.2. STATIC + ASYNC (po poprawkach â€” zgodne z kodem)
Lista krokÃ³w takÅ¼e pochodzi wyÅ‚Ä…cznie z payloadu.
Dispatcher wrzuca pierwsze kroki kaÅ¼dego pliku do kolejki crossbeam_channel.
Spawnowane sÄ… workery (max_workers).
KaÅ¼dy worker wykonuje:
pobranie zadania z kolejki
start_job(step)
poll_until_done(exec_id)
jeÅ›li istnieje kolejny krok:
wrzuÄ‡ go z powrotem do kolejki
jeÅ›li krokÃ³w nie ma:
remaining_files--
Konsekwencja:
âœ” kroki jednego pliku sÄ… wykonywane sekwencyjnie
âœ” pliki sÄ… wykonywane rÃ³wnolegle
Zero zapytaÅ„ do DB, bo workflow jest static.
4.3. DYNAMIC + BATCH
Dispatcher najpierw uruchamia pierwszy krok dla kaÅ¼dego pliku (z payloadu).
NastÄ™pnie pobiera peÅ‚nÄ… listÄ™ krokÃ³w z DB:
select get_payload_for_dispatcher_batch(file_watcher_id)
DB zwraca:
{
  file_id -> [seq2, seq3, ...]
}
Kroki sÄ… wykonywane SEQ po SEQ w batchach, dokÅ‚adnie jak w static batch.
DB jest pytane tylko raz po pierwszym batchu.
Przetwarzanie koÅ„czy siÄ™, gdy wszystkie SEQ zostanÄ… wykonane.
4.4. DYNAMIC + ASYNC
Pierwszy krok pochodzi z payloadu.
Po zakoÅ„czeniu tego joba worker robi:
get_steps_for_file(file_id)
i otrzymuje peÅ‚nÄ… listÄ™ krokÃ³w dla danego pliku.
Wstawia je do lokalnego cache (DashMap).
NastÄ™pnie worker wykonuje:
start_job â†’ poll_until_done â†’ enqueue(next_step)
aÅ¼ do wyczerpania listy.
DB jest pytane dokÅ‚adnie jeden raz per plik, tylko po pierwszym jobie.
Kroki lecÄ… sekwencyjnie, pliki rÃ³wnolegle.
ğŸŸ¦ 5. ModuÅ‚y przetwarzania (obrazy Cloud Run)
KaÅ¼dy krok workflow definiuje:
exec_object_nm â€“ nazwÄ™ joba Cloud Run (image)
process_cd â€“ typ procesu (extract/meta/export)
params â€“ parametry dodatkowe (np. trg_path)
W standardowym pipeline sÄ… 3 gÅ‚Ã³wne moduÅ‚y:
Extract Meta â€“ analiza i metadane pliku
Extract Data â€“ przetwarzanie wÅ‚aÅ›ciwe (np. OCR, parsing)
Export Meta â€“ zapis koÅ„cowych metadanych do GCS/DB
Dispatcher nie interpretuje logiki moduÅ‚Ã³w â€“ jego rolÄ… jest:
przekazaÄ‡ payload,
ustawiÄ‡ zmienne Å›rodowiskowe,
uruchomiÄ‡ job,
poczekaÄ‡ na wynik.
ğŸŸ¦ 6. Polling statusÃ³w jobÃ³w
Dispatcher nie uÅ¼ywa osobnego pollera â€“ polling wykonywany jest bezpoÅ›rednio w workerach, tuÅ¼ po:
exec_id = start_job(...)
poll_until_done(exec_id)
poll_until_done dziaÅ‚a nastÄ™pujÄ…co:
odpytuje Cloud Run Execution API
czeka aÅ¼ status joba bÄ™dzie:
SUCCEEDED â†’ krok zakoÅ„czony
FAILED â†’ error
uÅ¼ywa wartoÅ›ci timeout i interwaÅ‚u pollingowego zdefiniowanych w kodzie
po bÅ‚Ä™dzie ustawia globalny error_flag
Po powrocie z pollingu worker podejmuje decyzjÄ™:
enqueue nastÄ™pny krok
albo zakoÅ„cz plik
ğŸŸ¦ 7. ZakoÅ„czenie procesu
Po zakoÅ„czeniu caÅ‚ego workflow (niezaleÅ¼nie od trybu), Dispatcher:
Sprawdza globalny error_flag (atomic bool).
WywoÅ‚uje:
finish_process_f(process_exec_id, status_cd, error_msg, tech_update_id)
gdzie:
status_cd = COMPLETED jeÅ›li brak bÅ‚Ä™dÃ³w,
status_cd = ERROR jeÅ›li jakikolwiek krok zgÅ‚osiÅ‚ bÅ‚Ä…d.
error_msg ma postaÄ‡:
"One or more files failed"
Dispatcher koÅ„czy pracÄ™, a orkiestrator moÅ¼e odebraÄ‡ status z DB.
