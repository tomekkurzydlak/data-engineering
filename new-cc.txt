async fn run_static_wfl_async_jobs(&self, files: Vec<FileProcess>) -> Result<()> {
        // kolejka zadań (kroki do wykonania)
        let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
        // kolejka exec_id do centralnego pollera
        let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

        let remaining_files = Arc::new(AtomicUsize::new(files.len()));
        let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());

        // 1. Zbuduj steps_cache i wrzuć pierwszy krok dla każdego pliku
        for f in &files {
            if f.processes.is_empty() {
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                continue;
            }

            // sortujemy po seq
            let mut steps = f.processes.clone();
            steps.sort_by_key(|s| s.exec_process_seq);

            // pierwszy krok → osobno
            let first_step = steps.remove(0);

            // reszta kroków → do cache
            steps_cache.insert(f.file_id.clone(), steps.into());

            // wrzucamy pierwszy task
            tx_tasks.send(FileTask {
                file_id: f.file_id.clone(),
                gcs_file_uri: f.gcs_file_uri.clone(),
                step: first_step,
            })?;
        }

        drop(files);

        // 2. Poller – JEDEN wątek, który tylko polluje exec_id
        let rx_exec_for_poller = rx_exec.clone();
        let dispatcher_for_poller = self.clone_light();

        let poller_handle = std::thread::spawn(move || {
            let rt = tokio::runtime::Runtime::new()
                .expect("Nie udało się utworzyć Tokio Runtime dla pollera");

            while let Ok(exec_id) = rx_exec_for_poller.recv() {
                let backend = dispatcher_for_poller.backend.clone();

                rt.block_on(async {
                    if let Some(cr) = backend.as_any().downcast_ref::<CloudRunBackend>() {
                        if let Err(e) = cr
                            .poll_until_done(
                                &exec_id,
                                Duration::from_secs(60 * 30),
                                Duration::from_secs(10),
                            )
                            .await
                        {
                            error!(error = ?e, %exec_id, "STATIC+ASYNC poller: błąd poll_until_done");
                        }
                    } else {
                        debug!(%exec_id, "STATIC+ASYNC poller: backend bez poll_until_done");
                    }
                });
            }

            info!("STATIC+ASYNC poller: kanał exec_id zamknięty – kończę");
        });

        // 3. Spawn workerów
        let workers = self.cfg.max_workers;
        info!(workers, "STATIC+ASYNC: uruchamiam workerów");

        let mut worker_handles = Vec::new();

        for _ in 0..workers {
            let rx_tasks_clone = rx_tasks.clone();
            let tx_tasks_clone = tx_tasks.clone();
            let tx_exec_clone = tx_exec.clone();
            let dispatcher = self.clone_light();
            let remaining_files = Arc::clone(&remaining_files);
            let steps_cache = Arc::clone(&steps_cache);

            let h = std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new()
                    .expect("Nie udało się utworzyć Tokio Runtime dla workera (STATIC+ASYNC)");

                while let Ok(task) = rx_tasks_clone.recv() {
                    let dispatcher_cloned = dispatcher.clone_light();
                    let res = rt.block_on(async {
                        dispatcher_cloned
                            .process_static_task(
                                task,
                                &tx_tasks_clone,
                                &remaining_files,
                                &steps_cache,
                                &tx_exec_clone,
                            )
                            .await
                    });

                    if let Err(e) = res {
                        error!(error = ?e, "Błąd w workerze STATIC+ASYNC");
                    }
                }

                debug!("STATIC+ASYNC: worker zakończył pętlę (brak zadań)");
            });

            worker_handles.push(h);
        }

        // zamykamy główny sender zadań – workerzy zakończą się kiedy kolejka się wyczerpie
        drop(tx_tasks);
        // kiedy wszystkie klony tx_exec zostaną dropnięte (w workerach),
        // poller zobaczy błąd z recv() i zakończy pętlę

        // czekamy aż workerzy się zakończą
        for h in worker_handles {
            if let Err(e) = h.join() {
                error!("Join worker STATIC+ASYNC nie powiódł się: {:?}", e);
            }
        }

        // teraz możemy bezpiecznie zamknąć exec_tx w tym scope
        drop(tx_exec);

        // czekamy aż poller obrobi wszystkie exec_id
        if let Err(e) = poller_handle.join() {
            error!("Join poller STATIC+ASYNC nie powiódł się: {:?}", e);
        }

        info!(
            remaining = remaining_files.load(Ordering::Acquire),
            "STATIC+ASYNC: wszystkie zadania zakończone"
        );

        Ok(())
    }


=====

    async fn process_static_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        tx_exec: &Sender<String>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. przygotuj payload
        let payload = serde_json::json!({
            "process_id": self.cfg.process_id,
            "dispatcher_run_id": self.dispatcher_run_id.to_string(),
            "file_id": file_id,
            "gcs_file_uri": gcs_file_uri,
            "process_cd": step.process_cd,
            "seq": step.exec_process_seq,
        });

        let job_name = &step.exec_object_nm;

        // 2. env vars: na razie globalne; jeżeli masz TGT_PATH per step,
        //    to tutaj możesz dorzucić (mut envs = self.cfg.env_vars.clone(), envs.insert(...))
        let envs = self.cfg.env_vars.clone();

        // 3. start_job – bez pollingu
        let exec_id = if let Some(cr) = self
            .backend
            .as_any()
            .downcast_ref::<CloudRunBackend>()
        {
            cr.start_job(job_name, &payload, &envs).await?
        } else {
            self.backend.dispatch_job(job_name, &payload).await?
        };

        info!(
            %exec_id,
            %file_id,
            seq = step.exec_process_seq,
            obj = %step.exec_object_nm,
            "STATIC+ASYNC: job uruchomiony"
        );

        // 4. wysyłamy exec_id do centralnego pollera
        if let Err(e) = tx_exec.send(exec_id) {
            error!(error = ?e, "STATIC+ASYNC: nie udało się wysłać exec_id do pollera");
        }

        // 5. Kolejne kroki z cache – jak wcześniej
        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let new_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(new_task) {
                    error!(
                        error = ?e,
                        %file_id,
                        "STATIC+ASYNC: błąd wysyłania kolejnego kroku do kolejki"
                    );
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }

                return Ok(());
            } else {
                drop(entry);
                steps_cache.remove(file_id);
            }
        }

        // 6. Brak kolejnych kroków → plik zakończony
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        Ok(())
    }


=====

    async fn run_dynamic_wfl_async_jobs(&self, files: Vec<FileProcess>) -> Result<()> {
        let db = self
            .db
            .as_ref()
            .cloned()
            .ok_or_else(|| anyhow::anyhow!("Brak połączenia z DB dla dynamicznego workflow"))?;

        let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
        let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

        let remaining_files = Arc::new(AtomicUsize::new(files.len()));
        let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());

        // 1. wrzucamy pierwszy krok z payloadu dla każdego pliku
        for f in &files {
            if let Some(first_step) = f.processes.iter().min_by_key(|s| s.exec_process_seq) {
                let task = FileTask {
                    file_id: f.file_id.clone(),
                    gcs_file_uri: f.gcs_file_uri.clone(),
                    step: first_step.clone(),
                };
                if let Err(e) = tx_tasks.send(task) {
                    error!(error = ?e, "Błąd wysyłania początkowego zadania (DYNAMIC+ASYNC)");
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }
            } else {
                warn!(
                    file_id = %f.file_id,
                    "DYNAMIC+ASYNC: plik bez pierwszego kroku w payloadzie – traktuję jako zakończony"
                );
                remaining_files.fetch_sub(1, Ordering::AcqRel);
            }
        }

        drop(files);

        // 2. Poller
        let rx_exec_for_poller = rx_exec.clone();
        let dispatcher_for_poller = self.clone_light();

        let poller_handle = std::thread::spawn(move || {
            let rt = tokio::runtime::Runtime::new()
                .expect("Nie udało się utworzyć Tokio Runtime dla pollera (DYNAMIC+ASYNC)");

            while let Ok(exec_id) = rx_exec_for_poller.recv() {
                let backend = dispatcher_for_poller.backend.clone();

                rt.block_on(async {
                    if let Some(cr) = backend.as_any().downcast_ref::<CloudRunBackend>() {
                        if let Err(e) = cr
                            .poll_until_done(
                                &exec_id,
                                Duration::from_secs(60 * 30),
                                Duration::from_secs(10),
                            )
                            .await
                        {
                            error!(error = ?e, %exec_id, "DYNAMIC+ASYNC poller: błąd poll_until_done");
                        }
                    } else {
                        debug!(%exec_id, "DYNAMIC+ASYNC poller: backend bez poll_until_done");
                    }
                });
            }

            info!("DYNAMIC+ASYNC poller: kanał exec_id zamknięty – kończę");
        });

        // 3. workerzy
        let workers = self.cfg.max_workers;
        info!(workers, "DYNAMIC+ASYNC: uruchamiam workerów");

        let mut worker_handles = Vec::new();

        for _ in 0..workers {
            let rx_tasks_clone = rx_tasks.clone();
            let tx_tasks_clone = tx_tasks.clone();
            let tx_exec_clone = tx_exec.clone();
            let dispatcher = self.clone_light();
            let remaining_files = Arc::clone(&remaining_files);
            let steps_cache = Arc::clone(&steps_cache);
            let db_clone = db.clone();

            let h = std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new()
                    .expect("Nie udało się utworzyć Tokio Runtime dla workera (DYNAMIC+ASYNC)");

                while let Ok(task) = rx_tasks_clone.recv() {
                    let dispatcher_cloned = dispatcher.clone_light();
                    let db_for_call = db_clone.clone();

                    let res = rt.block_on(async {
                        dispatcher_cloned
                            .process_dynamic_task(
                                task,
                                &tx_tasks_clone,
                                &remaining_files,
                                &steps_cache,
                                &db_for_call,
                                &tx_exec_clone,
                            )
                            .await
                    });

                    if let Err(e) = res {
                        error!(error = ?e, "Błąd w workerze DYNAMIC+ASYNC");
                    }
                }

                debug!("DYNAMIC+ASYNC: worker zakończył pętlę (brak zadań)");
            });

            worker_handles.push(h);
        }

        drop(tx_tasks);
        // closing exec_tx dopiero po zakończeniu workerów

        for h in worker_handles {
            if let Err(e) = h.join() {
                error!("Join worker DYNAMIC+ASYNC nie powiódł się: {:?}", e);
            }
        }

        drop(tx_exec);

        if let Err(e) = poller_handle.join() {
            error!("Join poller DYNAMIC+ASYNC nie powiódł się: {:?}", e);
        }

        info!(
            remaining = remaining_files.load(Ordering::Acquire),
            "DYNAMIC+ASYNC: workerzy zakończeni"
        );

        Ok(())
    }


===

    async fn process_dynamic_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        db: &Arc<Db>,
        tx_exec: &Sender<String>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. uruchamiamy job dla bieżącego kroku
        let payload = serde_json::json!({
            "process_id": self.cfg.process_id,
            "dispatcher_run_id": self.dispatcher_run_id.to_string(),
            "file_id": file_id,
            "gcs_file_uri": gcs_file_uri,
            "process_cd": step.process_cd,
            "seq": step.exec_process_seq,
        });

        let job_name = &step.exec_object_nm;

        let envs = self.cfg.env_vars.clone();

        let exec_id = if let Some(cr) = self
            .backend
            .as_any()
            .downcast_ref::<CloudRunBackend>()
        {
            cr.start_job(job_name, &payload, &envs).await?
        } else {
            self.backend.dispatch_job(job_name, &payload).await?
        };

        info!(
            %exec_id,
            %file_id,
            seq = step.exec_process_seq,
            obj = %step.exec_object_nm,
            "DYNAMIC+ASYNC: job uruchomiony"
        );

        // wysyłamy exec_id do pollera
        if let Err(e) = tx_exec.send(exec_id) {
            error!(
                error = ?e,
                %file_id,
                "DYNAMIC+ASYNC: nie udało się wysłać exec_id do pollera"
            );
        }

        // 2. Po zakończeniu kroku – pobieramy (jeśli jeszcze nie ma) listę kolejnych kroków z DB
        if !steps_cache.contains_key(file_id) {
            let steps = db.get_steps_for_file(file_id).await?;
            if steps.is_empty() {
                debug!(%file_id, "DYNAMIC+ASYNC: brak kolejnych kroków w DB");
                let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
                info!(
                    %file_id,
                    prev_remaining = prev,
                    "DYNAMIC+ASYNC: plik zakończony (brak kroków)"
                );
                return Ok(());
            } else {
                let mut v: Vec<ProcessStep> = steps;
                v.sort_by_key(|s| s.exec_process_seq);
                steps_cache.insert(file_id.clone(), v.into());
            }
        }

        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let new_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(new_task) {
                    error!(
                        error = ?e,
                        %file_id,
                        "DYNAMIC+ASYNC: błąd wysyłania kolejnego kroku do kolejki"
                    );
                    let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
                    info!(
                        %file_id,
                        prev_remaining = prev,
                        "DYNAMIC+ASYNC: plik zakończony z błędem send()"
                    );
                }
            } else {
                drop(entry);
                steps_cache.remove(file_id);
                let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
                info!(
                    %file_id,
                    prev_remaining = prev,
                    "DYNAMIC+ASYNC: plik zakończony (kolejka kroków pusta)"
                );
            }
        } else {
            let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
            info!(
                %file_id,
                prev_remaining = prev,
                "DYNAMIC+ASYNC: plik zakończony (brak entry w cache)"
            );
        }

        Ok(())
    }


