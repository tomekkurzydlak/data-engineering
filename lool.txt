let h = std::thread::spawn(move || {
    let rt = tokio::runtime::Runtime::new()
        .expect("Tokio Runtime worker error");

    loop {
        // jeśli już nie ma żadnych plików do obsługi – kończymy worker
        if remaining_files.load(Ordering::Acquire) == 0 {
            break;
        }

        match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
            Ok(task) => {
                let dispatcher_c = dispatcher.clone_light();

                let res = rt.block_on(async {
                    dispatcher_c
                        .process_static_task(
                            task,
                            &tx_tasks_clone,
                            &remaining_files,
                            &steps_cache,
                            &tx_exec_clone,
                        )
                        .await
                });

                if let Err(e) = res {
                    error!(error = ?e, "STATIC+ASYNC worker error");
                    // to już masz – ale zostawiamy to tu jawnie:
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }
            }
            Err(RecvTimeoutError::Timeout) => {
                // po prostu odpalamy kolejną iterację,
                // ale jeśli remaining_files == 0, wyjdziemy na początku pętli
                continue;
            }
            Err(RecvTimeoutError::Disconnected) => {
                // kanał zamknięty – nie będzie więcej tasków
                break;
            }
        }
    }
});


=====

let h = std::thread::spawn(move || {
    let rt = tokio::runtime::Runtime::new()
        .expect("Tokio Runtime worker dynamic");

    loop {
        if remaining_files.load(Ordering::Acquire) == 0 {
            break;
        }

        match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
            Ok(task) => {
                let dispatcher_c = dispatcher.clone_light();
                let db_for_call = db_clone.clone();

                let res = rt.block_on(async {
                    dispatcher_c
                        .process_dynamic_task(
                            task,
                            &tx_tasks_clone,
                            &remaining_files,
                            &steps_cache,
                            &db_for_call,
                            &tx_exec_clone,
                        )
                        .await
                });

                if res.is_err() {
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }
            }
            Err(RecvTimeoutError::Timeout) => {
                // sprawdzimy remaining_files na górze pętli
                continue;
            }
            Err(RecvTimeoutError::Disconnected) => {
                break;
            }
        }
    }
});

====


global_flg:

async fn run_dynamic_wfl_async_jobs(&self, files: Vec<FileProcess>) -> Result<Arc<AtomicBool>> {
    let db = self
        .db
        .as_ref()
        .cloned()
        .ok_or_else(|| anyhow::anyhow!("Brak połączenia z DB dla dynamicznego workflow"))?;

    let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
    let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

    let remaining_files = Arc::new(AtomicUsize::new(files.len()));
    let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());
    let error_flag = Arc::new(AtomicBool::new(false));

    // =============================================================
    // 1. pierwszy krok per file z payloadu
    // =============================================================
    for f in &files {
        if let Some(first_step) = f.processes.iter().min_by_key(|s| s.exec_process_seq) {
            let task = FileTask {
                file_id: f.file_id.clone(),
                gcs_file_uri: f.gcs_file_uri.clone(),
                step: first_step.clone(),
            };
            let _ = tx_tasks.send(task);
        } else {
            remaining_files.fetch_sub(1, Ordering::AcqRel);
        }
    }

    drop(files);

    // =============================================================
    // 2. Poller
    // =============================================================
    let rx_exec_for_poller = rx_exec.clone();
    let dispatcher_for_poller = self.clone_light();
    let error_flag_for_poller = error_flag.clone();

    let poller_handle = tokio::spawn(async move {
        loop {
            let maybe_id = tokio::task::spawn_blocking({
                let rx = rx_exec_for_poller.clone();
                move || rx.recv()
            })
            .await;

            let exec_id = match maybe_id {
                Ok(Ok(id)) => id,
                Ok(Err(_)) => break,
                Err(e) => {
                    error!(?e, "DYNAMIC+ASYNC poller: JoinError");
                    error_flag_for_poller.store(true, Ordering::SeqCst);
                    break;
                }
            };

            if let Some(cr) = dispatcher_for_poller
                .backend
                .as_any()
                .downcast_ref::<CloudRunBackend>()
            {
                if let Err(e) = cr
                    .poll_until_done(
                        &exec_id,
                        Duration::from_secs(1800),
                        Duration::from_secs(10),
                    )
                    .await
                {
                    error!(?e, %exec_id, "DYNAMIC+ASYNC poller: błąd poll");
                    error_flag_for_poller.store(true, Ordering::SeqCst);
                }
            }
        }
    });

    // =============================================================
    // 3. Workers
    // =============================================================

    let mut worker_handles = Vec::new();

    for _ in 0..self.cfg.max_workers {
        let rx_tasks_clone = rx_tasks.clone();
        let tx_tasks_clone = tx_tasks.clone();
        let tx_exec_clone = tx_exec.clone();
        let dispatcher = self.clone_light();
        let remaining_files = Arc::clone(&remaining_files);
        let steps_cache = Arc::clone(&steps_cache);
        let db_clone = db.clone();
        let error_flag = error_flag.clone();

        let h = std::thread::spawn(move || {
            let rt = tokio::runtime::Runtime::new()
                .expect("Tokio Runtime worker dynamic");

            loop {
                if remaining_files.load(Ordering::Acquire) == 0 {
                    break;
                }

                match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
                    Ok(task) => {
                        let dispatcher_c = dispatcher.clone_light();
                        let db_for_call = db_clone.clone();

                        let res = rt.block_on(async {
                            dispatcher_c
                                .process_dynamic_task(
                                    task,
                                    &tx_tasks_clone,
                                    &remaining_files,
                                    &steps_cache,
                                    &db_for_call,
                                    &tx_exec_clone,
                                    &error_flag,
                                )
                                .await
                        });

                        if let Err(e) = res {
                            error!(error=?e, "DYNAMIC+ASYNC worker error");
                            error_flag.store(true, Ordering::SeqCst);
                            remaining_files.fetch_sub(1, Ordering::AcqRel);
                        }
                    }
                    Err(RecvTimeoutError::Timeout) => continue,
                    Err(RecvTimeoutError::Disconnected) => break,
                }
            }
        });

        worker_handles.push(h);
    }

    drop(tx_tasks);

    for h in worker_handles {
        let _ = h.join();
    }

    drop(tx_exec);

    let _ = poller_handle.await;

    info!(
        remaining = remaining_files.load(Ordering::Acquire),
        "DYNAMIC+ASYNC zakończone"
    );

    Ok(error_flag)
}


====



async fn process_dynamic_task(
    &self,
    task: FileTask,
    tx_tasks: &Sender<FileTask>,
    remaining_files: &Arc<AtomicUsize>,
    steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
    db: &Arc<Db>,
    tx_exec: &Sender<String>,
    error_flag: &Arc<AtomicBool>,
) -> Result<()> {
    let file_id = &task.file_id;
    let gcs_file_uri = &task.gcs_file_uri;
    let step = &task.step;

    // =============================================================
    // 1. ENV VARS per step
    // =============================================================
    let mut envs = self.cfg.env_vars.clone();
    let tgt_path = step
        .params
        .get("trg_path")
        .and_then(|v| v.as_str())
        .unwrap_or("");
    envs.insert("TGT_PATH".into(), tgt_path.to_string());

    let payload = serde_json::json!({
        "process_id": self.cfg.process_id,
        "dispatcher_run_id": self.dispatcher_run_id.to_string(),
        "file_id": file_id,
        "gcs_file_uri": gcs_file_uri,
        "process_cd": step.process_cd,
        "seq": step.exec_process_seq,
    });

    let job_name = &step.exec_object_nm;

    // =============================================================
    // 2. start_job / dispatch_job
    // =============================================================
    let exec_id = match self.backend.as_any().downcast_ref::<CloudRunBackend>() {
        Some(cr) => {
            match cr.start_job(job_name, &payload, &envs).await {
                Ok(id) => id,
                Err(e) => {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd start_job");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            }
        }
        None => {
            match self.backend.dispatch_job(job_name, &payload).await {
                Ok(id) => id,
                Err(e) => {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd dispatch_job");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            }
        }
    };

    info!(
        %exec_id,
        %file_id,
        seq = step.exec_process_seq,
        obj = %step.exec_object_nm,
        "DYNAMIC+ASYNC: job uruchomiony"
    );

    // =============================================================
    // 3. wysyłamy exec_id do pollera
    // =============================================================
    if let Err(e) = tx_exec.send(exec_id) {
        error!(error=?e, %file_id, "DYNAMIC+ASYNC: nie udało się wysłać exec_id do pollera");
        error_flag.store(true, Ordering::SeqCst);
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        return Err(anyhow::anyhow!("Kanał pollera zamknięty"));
    }

    // =============================================================
    // 4. jeśli brak entry w cache → pobieramy z DB
    // =============================================================
    if !steps_cache.contains_key(file_id) {
        let steps = match db.get_steps_for_file(file_id).await {
            Ok(s) => s,
            Err(e) => {
                error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd get_steps_for_file");
                error_flag.store(true, Ordering::SeqCst);
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                return Err(e);
            }
        };

        if steps.is_empty() {
            let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
            info!(%file_id, prev_remaining=%prev, "DYNAMIC+ASYNC: brak dalszych kroków — koniec pliku");
            return Ok(());
        }

        let mut sorted = steps;
        sorted.sort_by_key(|s| s.exec_process_seq);
        steps_cache.insert(file_id.clone(), sorted.into());
    }

    // =============================================================
    // 5. enqueue next step
    // =============================================================
    if let Some(mut entry) = steps_cache.get_mut(file_id) {
        if let Some(next_step) = entry.pop_front() {
            let queue_empty = entry.is_empty();
            drop(entry);
            if queue_empty {
                steps_cache.remove(file_id);
            }

            let next_task = FileTask {
                file_id: file_id.clone(),
                gcs_file_uri: gcs_file_uri.clone(),
                step: next_step,
            };

            if let Err(e) = tx_tasks.send(next_task) {
                error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd wysłania kolejnego kroku");
                error_flag.store(true, Ordering::SeqCst);
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                return Err(anyhow::anyhow!("Kanał workerów zamknięty"));
            }

            return Ok(());
        } else {
            drop(entry);
            steps_cache.remove(file_id);
        }
    }

    // =============================================================
    // 6. koniec pliku
    // =============================================================
    remaining_files.fetch_sub(1, Ordering::AcqRel);
    Ok(())
}



====


async fn process_static_task(
    &self,
    task: FileTask,
    tx_tasks: &Sender<FileTask>,
    remaining_files: &Arc<AtomicUsize>,
    steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
    tx_exec: &Sender<String>,
    error_flag: &Arc<AtomicBool>,
) -> Result<()> {
    let file_id = &task.file_id;
    let gcs_file_uri = &task.gcs_file_uri;
    let step = &task.step;

    // =============================================================
    // 1. ENV vars per step
    // =============================================================
    let mut envs = self.cfg.env_vars.clone();
    let tgt_path = step.params
        .get("trg_path")
        .and_then(|v| v.as_str())
        .unwrap_or("");
    envs.insert("TGT_PATH".into(), tgt_path.to_string());

    let payload = serde_json::json!({
        "process_id": self.cfg.process_id,
        "dispatcher_run_id": self.dispatcher_run_id.to_string(),
        "file_id": file_id,
        "gcs_file_uri": gcs_file_uri,
        "process_cd": step.process_cd,
        "seq": step.exec_process_seq,
    });

    let job_name = &step.exec_object_nm;

    // =============================================================
    // 2. start_job
    // =============================================================
    let exec_id = match self.backend.as_any().downcast_ref::<CloudRunBackend>() {
        Some(cr) => match cr.start_job(job_name, &payload, &envs).await {
            Ok(id) => id,
            Err(e) => {
                error!(error=?e, %file_id, "STATIC+ASYNC: błąd start_job");
                error_flag.store(true, Ordering::SeqCst);
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                return Err(e);
            }
        },
        None => match self.backend.dispatch_job(job_name, &payload).await {
            Ok(id) => id,
            Err(e) => {
                error!(error=?e, %file_id, "STATIC+ASYNC: błąd dispatch_job");
                error_flag.store(true, Ordering::SeqCst);
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                return Err(e);
            }
        }
    };

    info!(
        %exec_id,
        %file_id,
        seq = step.exec_process_seq,
        obj = %step.exec_object_nm,
        "STATIC+ASYNC: job uruchomiony"
    );

    // =============================================================
    // 3. wysłanie exec_id do pollera
    // =============================================================
    if let Err(e) = tx_exec.send(exec_id) {
        error!(error=?e, %file_id, "STATIC+ASYNC: błąd wysyłania exec_id do pollera");
        error_flag.store(true, Ordering::SeqCst);
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        return Err(anyhow::anyhow!("STATIC+ASYNC: poller channel closed"));
    }

    // =============================================================
    // 4. Kolejny krok
    // =============================================================
    if let Some(mut entry) = steps_cache.get_mut(file_id) {
        if let Some(next_step) = entry.pop_front() {
            let queue_empty = entry.is_empty();
            drop(entry);
            if queue_empty {
                steps_cache.remove(file_id);
            }

            let new_task = FileTask {
                file_id: file_id.clone(),
                gcs_file_uri: gcs_file_uri.clone(),
                step: next_step,
            };

            if let Err(e) = tx_tasks.send(new_task) {
                error!(error=?e, %file_id, "STATIC+ASYNC: błąd wysyłania next_step");
                error_flag.store(true, Ordering::SeqCst);
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                return Err(anyhow::anyhow!("STATIC+ASYNC: task channel closed"));
            }

            return Ok(()); // kolejny krok wrzucony – plik trwa dalej
        } else {
            drop(entry);
            steps_cache.remove(file_id);
        }
    }

    // =============================================================
    // 5. Brak kolejnych kroków → koniec pliku
    // =============================================================
    remaining_files.fetch_sub(1, Ordering::AcqRel);
    Ok(())
}
