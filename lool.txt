let h = std::thread::spawn(move || {
    let rt = tokio::runtime::Runtime::new()
        .expect("Tokio Runtime worker error");

    loop {
        // jeśli już nie ma żadnych plików do obsługi – kończymy worker
        if remaining_files.load(Ordering::Acquire) == 0 {
            break;
        }

        match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
            Ok(task) => {
                let dispatcher_c = dispatcher.clone_light();

                let res = rt.block_on(async {
                    dispatcher_c
                        .process_static_task(
                            task,
                            &tx_tasks_clone,
                            &remaining_files,
                            &steps_cache,
                            &tx_exec_clone,
                        )
                        .await
                });

                if let Err(e) = res {
                    error!(error = ?e, "STATIC+ASYNC worker error");
                    // to już masz – ale zostawiamy to tu jawnie:
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }
            }
            Err(RecvTimeoutError::Timeout) => {
                // po prostu odpalamy kolejną iterację,
                // ale jeśli remaining_files == 0, wyjdziemy na początku pętli
                continue;
            }
            Err(RecvTimeoutError::Disconnected) => {
                // kanał zamknięty – nie będzie więcej tasków
                break;
            }
        }
    }
});


=====

let h = std::thread::spawn(move || {
    let rt = tokio::runtime::Runtime::new()
        .expect("Tokio Runtime worker dynamic");

    loop {
        if remaining_files.load(Ordering::Acquire) == 0 {
            break;
        }

        match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
            Ok(task) => {
                let dispatcher_c = dispatcher.clone_light();
                let db_for_call = db_clone.clone();

                let res = rt.block_on(async {
                    dispatcher_c
                        .process_dynamic_task(
                            task,
                            &tx_tasks_clone,
                            &remaining_files,
                            &steps_cache,
                            &db_for_call,
                            &tx_exec_clone,
                        )
                        .await
                });

                if res.is_err() {
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                }
            }
            Err(RecvTimeoutError::Timeout) => {
                // sprawdzimy remaining_files na górze pętli
                continue;
            }
            Err(RecvTimeoutError::Disconnected) => {
                break;
            }
        }
    }
});

====


global_flg:

async fn run_dynamic_wfl_async_jobs(&self, files: Vec<FileProcess>) -> Result<Arc<AtomicBool>> {
    let db = self
        .db
        .as_ref()
        .cloned()
        .ok_or_else(|| anyhow::anyhow!("Brak połączenia z DB dla dynamicznego workflow"))?;

    let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();
    let (tx_exec, rx_exec): (Sender<String>, Receiver<String>) = unbounded();

    let remaining_files = Arc::new(AtomicUsize::new(files.len()));
    let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());
    let error_flag = Arc::new(AtomicBool::new(false));

    // =============================================================
    // 1. pierwszy krok per file z payloadu
    // =============================================================
    for f in &files {
        if let Some(first_step) = f.processes.iter().min_by_key(|s| s.exec_process_seq) {
            let task = FileTask {
                file_id: f.file_id.clone(),
                gcs_file_uri: f.gcs_file_uri.clone(),
                step: first_step.clone(),
            };
            let _ = tx_tasks.send(task);
        } else {
            remaining_files.fetch_sub(1, Ordering::AcqRel);
        }
    }

    drop(files);

    // =============================================================
    // 2. Poller
    // =============================================================
    let rx_exec_for_poller = rx_exec.clone();
    let dispatcher_for_poller = self.clone_light();
    let error_flag_for_poller = error_flag.clone();

    let poller_handle = tokio::spawn(async move {
        loop {
            let maybe_id = tokio::task::spawn_blocking({
                let rx = rx_exec_for_poller.clone();
                move || rx.recv()
            })
            .await;

            let exec_id = match maybe_id {
                Ok(Ok(id)) => id,
                Ok(Err(_)) => break,
                Err(e) => {
                    error!(?e, "DYNAMIC+ASYNC poller: JoinError");
                    error_flag_for_poller.store(true, Ordering::SeqCst);
                    break;
                }
            };

            if let Some(cr) = dispatcher_for_poller
                .backend
                .as_any()
                .downcast_ref::<CloudRunBackend>()
            {
                if let Err(e) = cr
                    .poll_until_done(
                        &exec_id,
                        Duration::from_secs(1800),
                        Duration::from_secs(10),
                    )
                    .await
                {
                    error!(?e, %exec_id, "DYNAMIC+ASYNC poller: błąd poll");
                    error_flag_for_poller.store(true, Ordering::SeqCst);
                }
            }
        }
    });

    // =============================================================
    // 3. Workers
    // =============================================================

    let mut worker_handles = Vec::new();

    for _ in 0..self.cfg.max_workers {
        let rx_tasks_clone = rx_tasks.clone();
        let tx_tasks_clone = tx_tasks.clone();
        let tx_exec_clone = tx_exec.clone();
        let dispatcher = self.clone_light();
        let remaining_files = Arc::clone(&remaining_files);
        let steps_cache = Arc::clone(&steps_cache);
        let db_clone = db.clone();
        let error_flag = error_flag.clone();

        let h = std::thread::spawn(move || {
            let rt = tokio::runtime::Runtime::new()
                .expect("Tokio Runtime worker dynamic");

            loop {
                if remaining_files.load(Ordering::Acquire) == 0 {
                    break;
                }

                match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
                    Ok(task) => {
                        let dispatcher_c = dispatcher.clone_light();
                        let db_for_call = db_clone.clone();

                        let res = rt.block_on(async {
                            dispatcher_c
                                .process_dynamic_task(
                                    task,
                                    &tx_tasks_clone,
                                    &remaining_files,
                                    &steps_cache,
                                    &db_for_call,
                                    &tx_exec_clone,
                                    &error_flag,
                                )
                                .await
                        });

                        if let Err(e) = res {
                            error!(error=?e, "DYNAMIC+ASYNC worker error");
                            error_flag.store(true, Ordering::SeqCst);
                            remaining_files.fetch_sub(1, Ordering::AcqRel);
                        }
                    }
                    Err(RecvTimeoutError::Timeout) => continue,
                    Err(RecvTimeoutError::Disconnected) => break,
                }
            }
        });

        worker_handles.push(h);
    }

    drop(tx_tasks);

    for h in worker_handles {
        let _ = h.join();
    }

    drop(tx_exec);

    let _ = poller_handle.await;

    info!(
        remaining = remaining_files.load(Ordering::Acquire),
        "DYNAMIC+ASYNC zakończone"
    );

    Ok(error_flag)
}


