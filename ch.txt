    async fn run(&self, files: Vec<FileProcess>) -> Result<()> {
        info!("Rozpoczynam przetwarzanie plików...");

        // globalny znacznik błędu dla trybów ASYNC (na przyszłość, np. do logów)
        let error_flag = Arc::new(AtomicBool::new(false));

        match (self.cfg.workflow_type, self.cfg.dispatch_mode) {
            (WorkflowType::Static, DispatchMode::Batch) => {
                self.run_static_wfl_batch_jobs(&files).await?
            }
            (WorkflowType::Static, DispatchMode::Async) => {
                self.run_static_wfl_async_jobs(files, error_flag.clone()).await?
            }
            (WorkflowType::Dynamic, DispatchMode::Batch) => {
                self.run_dynamic_wfl_batch_jobs(files).await?
            }
            (WorkflowType::Dynamic, DispatchMode::Async) => {
                self.run_dynamic_wfl_async_jobs(files, error_flag.clone()).await?
            }
        }

        // Tutaj już NIE wywołujemy start/finish_process_f – jest per krok
        let any_error = error_flag.load(Ordering::SeqCst);
        if any_error {
            warn!("Run zakończony z błędami (sprawdź logi oraz statusy kroków w DB)");
        } else {
            info!("Run zakończony poprawnie");
        }

        Ok(())
    }


===


dynamic+batch - ostatni loop:

        //
        // 3. Kolejne batche — dopóki istnieją jakieś kroki
        //
        loop {
            let mut batch: Vec<(String, String, ProcessStep)> = Vec::new();

            for (file_id, (uri, dq)) in steps_map.iter_mut() {
                let prev_seq = *last_seq.get(file_id).unwrap_or(&0);

                if let Some(next_step) = dq.pop_front() {
                    if next_step.exec_process_seq > prev_seq {
                        last_seq.insert(file_id.clone(), next_step.exec_process_seq);
                        batch.push((file_id.clone(), uri.clone(), next_step));
                    } else {
                        warn!(
                            %file_id,
                            prev_seq,
                            next = next_step.exec_process_seq,
                            "DYNAMIC+BATCH: krok z DB ma seq <= poprzedni — pomijam"
                        );
                    }
                }
            }

            // Wyczyszczenie mapy z pustych kolejek
            steps_map.retain(|_, (_, dq)| !dq.is_empty());

            if batch.is_empty() {
                info!("DYNAMIC+BATCH: brak kolejnych kroków — pipeline zakończony");
                break;
            }

            let process_cd = batch[0].2.process_cd.clone();
            let seq = batch[0].2.exec_process_seq;

            info!(
                count = batch.len(),
                %process_cd,
                seq,
                "DYNAMIC+BATCH: uruchamiam batch kolejnych kroków (krok)"
            );

            if let Some(db) = &self.db {
                let file_watcher_id = self.cfg.file_watcher_id.unwrap_or(0);
                let tech_insert_id = self.cfg.tech_insert_id.unwrap_or(0);

                let pid = db
                    .init_session(&process_cd, file_watcher_id, tech_insert_id)
                    .await
                    .context("DYNAMIC+BATCH: błąd start_process_f dla kroku")?;

                let result = self.run_batch_for_steps(&batch).await;

                let tech_update_id = self
                    .cfg
                    .tech_update_id
                    .or(self.cfg.tech_insert_id)
                    .unwrap_or(0);

                let (status_cd, error_msg) = match &result {
                    Ok(_) => ("COMPLETED", "".to_string()),
                    Err(e) => ("ERROR", e.to_string()),
                };

                if let Err(e) = db
                    .end_session(pid, status_cd, &error_msg, tech_update_id)
                    .await
                {
                    error!(error=?e, %pid, "DYNAMIC+BATCH: błąd finish_process_f dla kroku");
                }

                result?;
            } else {
                self.run_batch_for_steps(&batch).await?;
            }
        }

        Ok(())
    }


=====

    async fn run_static_wfl_batch_jobs(&self, files: &[FileProcess]) -> Result<()> {
        let seqs = Self::collect_sorted_seqs(files);

        for seq in seqs {
            // zbierz wszystkie kroki o danym seq
            let mut steps_vec: Vec<(String, String, ProcessStep)> = Vec::new();
            for f in files {
                for p in &f.processes {
                    if p.exec_process_seq == seq {
                        steps_vec.push((f.file_id.clone(), f.gcs_file_uri.clone(), p.clone()));
                    }
                }
            }

            if steps_vec.is_empty() {
                continue;
            }

            // process_cd bierzemy z pierwszego kroku
            let process_cd = steps_vec[0].2.process_cd.clone();

            info!(
                seq,
                count = steps_vec.len(),
                %process_cd,
                "STATIC+BATCH: uruchamiam batch dla seq (krok)"
            );

            // Sesja w DB per krok (jeśli DB jest dostępne)
            if let Some(db) = &self.db {
                let file_watcher_id = self.cfg.file_watcher_id.unwrap_or(0);
                let tech_insert_id = self.cfg.tech_insert_id.unwrap_or(0);

                let pid = db
                    .init_session(&process_cd, file_watcher_id, tech_insert_id)
                    .await
                    .context("STATIC+BATCH: błąd start_process_f dla kroku")?;

                let result = self.run_batch_for_steps(&steps_vec).await;

                let tech_update_id = self
                    .cfg
                    .tech_update_id
                    .or(self.cfg.tech_insert_id)
                    .unwrap_or(0);

                let (status_cd, error_msg) = match &result {
                    Ok(_) => ("COMPLETED", "".to_string()),
                    Err(e) => ("ERROR", e.to_string()),
                };

                if let Err(e) = db
                    .end_session(pid, status_cd, &error_msg, tech_update_id)
                    .await
                {
                    error!(error=?e, %pid, "STATIC+BATCH: błąd finish_process_f dla kroku");
                }

                result?;
            } else {
                // Brak DB → tylko batch
                self.run_batch_for_steps(&steps_vec).await?;
            }
        }

        Ok(())
    }


===


    async fn process_dynamic_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        db: &Arc<Db>,
        error_flag: &Arc<AtomicBool>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. Wykonanie kroku z sesją DB
        if let Err(e) = self
            .execute_step_with_session(file_id, gcs_file_uri, step)
            .await
        {
            error!(
                error=?e,
                %file_id,
                seq = step.exec_process_seq,
                "DYNAMIC+ASYNC: błąd wykonania kroku"
            );
            error_flag.store(true, Ordering::SeqCst);
            remaining_files.fetch_sub(1, Ordering::AcqRel);
            return Err(e);
        }

        // 2. jeśli brak entry w cache → pobieramy z DB (bez zmian)
        if !steps_cache.contains_key(file_id) {
            let steps = match db.get_steps_for_file(file_id).await {
                Ok(s) => s,
                Err(e) => {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd get_steps_for_file");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(e);
                }
            };

            if steps.is_empty() {
                let prev = remaining_files.fetch_sub(1, Ordering::AcqRel);
                info!(%file_id, prev_remaining=%prev, "DYNAMIC+ASYNC: brak dalszych kroków — koniec pliku");
                return Ok(());
            }

            let mut sorted = steps;
            sorted.sort_by_key(|s| s.exec_process_seq);
            steps_cache.insert(file_id.clone(), sorted.into());
        }

        // 3. enqueue next step (bez zmian)
        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let next_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(next_task) {
                    error!(error=?e, %file_id, "DYNAMIC+ASYNC: błąd wysłania kolejnego kroku");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(anyhow::anyhow!("Kanał workerów zamknięty"));
                }

                return Ok(());
            } else {
                drop(entry);
                steps_cache.remove(file_id);
            }
        }

        // 4. koniec pliku
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        Ok(())
    }


====

    async fn process_static_task(
        &self,
        task: FileTask,
        tx_tasks: &Sender<FileTask>,
        remaining_files: &Arc<AtomicUsize>,
        steps_cache: &Arc<DashMap<String, VecDeque<ProcessStep>>>,
        error_flag: &Arc<AtomicBool>,
    ) -> Result<()> {
        let file_id = &task.file_id;
        let gcs_file_uri = &task.gcs_file_uri;
        let step = &task.step;

        // 1. Wykonanie kroku z sesją DB
        if let Err(e) = self
            .execute_step_with_session(file_id, gcs_file_uri, step)
            .await
        {
            error!(
                error=?e,
                %file_id,
                seq = step.exec_process_seq,
                "STATIC+ASYNC: błąd wykonania kroku"
            );
            error_flag.store(true, Ordering::SeqCst);
            remaining_files.fetch_sub(1, Ordering::AcqRel);
            return Err(e);
        }

        // 2. Kolejny krok (jeśli jest)
        if let Some(mut entry) = steps_cache.get_mut(file_id) {
            if let Some(next_step) = entry.pop_front() {
                let queue_empty = entry.is_empty();
                drop(entry);
                if queue_empty {
                    steps_cache.remove(file_id);
                }

                let new_task = FileTask {
                    file_id: file_id.clone(),
                    gcs_file_uri: gcs_file_uri.clone(),
                    step: next_step,
                };

                if let Err(e) = tx_tasks.send(new_task) {
                    error!(error=?e, %file_id, "STATIC+ASYNC: błąd wysyłania next_step");
                    error_flag.store(true, Ordering::SeqCst);
                    remaining_files.fetch_sub(1, Ordering::AcqRel);
                    return Err(anyhow::anyhow!("STATIC+ASYNC: task channel closed"));
                }

                return Ok(());
            } else {
                drop(entry);
                steps_cache.remove(file_id);
            }
        }

        // 3. Brak kolejnych kroków → koniec pliku
        remaining_files.fetch_sub(1, Ordering::AcqRel);
        Ok(())
    }



===


    async fn run_static_wfl_async_jobs(
        &self,
        files: Vec<FileProcess>,
        error_flag: Arc<AtomicBool>,
    ) -> Result<()> {
        let (tx_tasks, rx_tasks): (Sender<FileTask>, Receiver<FileTask>) = unbounded();

        let remaining_files = Arc::new(AtomicUsize::new(files.len()));
        let steps_cache: Arc<DashMap<String, VecDeque<ProcessStep>>> = Arc::new(DashMap::new());

        // 1. pierwszy krok dla każdego pliku
        for f in &files {
            if f.processes.is_empty() {
                remaining_files.fetch_sub(1, Ordering::AcqRel);
                continue;
            }

            let mut steps = f.processes.clone();
            steps.sort_by_key(|s| s.exec_process_seq);

            let first_step = steps.remove(0);
            steps_cache.insert(f.file_id.clone(), steps.into());

            tx_tasks.send(FileTask {
                file_id: f.file_id.clone(),
                gcs_file_uri: f.gcs_file_uri.clone(),
                step: first_step,
            })?;
        }

        drop(files);

        // 2. Worker pool (bez osobnego pollera)
        let workers = self.cfg.max_workers;
        let mut worker_handles = Vec::new();

        for _ in 0..workers {
            let rx_tasks_clone = rx_tasks.clone();
            let tx_tasks_clone = tx_tasks.clone();
            let dispatcher = self.clone_light();
            let remaining_files = Arc::clone(&remaining_files);
            let steps_cache = Arc::clone(&steps_cache);
            let error_flag = error_flag.clone();

            let h = std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new()
                    .expect("Tokio Runtime worker error");

                loop {
                    if remaining_files.load(Ordering::Acquire) == 0 {
                        break;
                    }

                    match rx_tasks_clone.recv_timeout(Duration::from_secs(1)) {
                        Ok(task) => {
                            let dispatcher_c = dispatcher.clone_light();

                            let res = rt.block_on(async {
                                dispatcher_c
                                    .process_static_task(
                                        task,
                                        &tx_tasks_clone,
                                        &remaining_files,
                                        &steps_cache,
                                        &error_flag,
                                    )
                                    .await
                            });

                            if let Err(e) = res {
                                error!(error = ?e, "STATIC+ASYNC worker error");
                            }
                        }
                        Err(RecvTimeoutError::Timeout) => {
                            continue;
                        }
                        Err(RecvTimeoutError::Disconnected) => {
                            break;
                        }
                    }
                }
            });

            worker_handles.push(h);
        }

        drop(tx_tasks);

        for h in worker_handles {
            let _ = h.join();
        }

        info!(
            remaining = remaining_files.load(Ordering::Acquire),
            "STATIC+ASYNC zakończone"
        );
        Ok(())
    }



====

impl Dispatcher {
    // ... clone_light itd.

    /// Wykonanie pojedynczego kroku w Cloud Run (bez logiki DB).
    async fn execute_step_cloud_run(
        &self,
        file_id: &str,
        gcs_file_uri: &str,
        step: &ProcessStep,
    ) -> Result<()> {
        // 1. ENV vars per step
        let mut envs = self.cfg.env_vars.clone();
        let tgt_path = step
            .params
            .get("trg_path")
            .and_then(|v| v.as_str())
            .unwrap_or("");

        envs.insert("TGT_PATH".into(), tgt_path.to_string());

        // 2. Payload
        let payload = serde_json::json!({
            "process_id": self.cfg.process_id,
            "dispatcher_run_id": self.dispatcher_run_id.to_string(),
            "file_id": file_id,
            "gcs_file_uri": gcs_file_uri,
            "process_cd": step.process_cd,
            "seq": step.exec_process_seq,
        });

        let job_name = &step.exec_object_nm;

        // 3. start_job / dispatch_job
        let exec_id = match self.backend.as_any().downcast_ref::<CloudRunBackend>() {
            Some(cr) => {
                let id = cr.start_job(job_name, &payload, &envs).await?;
                info!(
                    %id,
                    %file_id,
                    seq = step.exec_process_seq,
                    obj = %step.exec_object_nm,
                    "STEP: job uruchomiony (Cloud Run)"
                );
                // Pollujemy tutaj — sekwencyjnie per krok
                cr.poll_until_done(
                    &id,
                    Duration::from_secs(1800),      // timeout
                    Duration::from_secs(10),        // poll interval
                )
                .await?;
                id
            }
            None => {
                let id = self.backend.dispatch_job(job_name, &payload).await?;
                info!(
                    %id,
                    %file_id,
                    seq = step.exec_process_seq,
                    obj = %step.exec_object_nm,
                    "STEP: job uruchomiony (inny backend, bez pollingu)"
                );
                id
            }
        };

        debug!(%exec_id, %file_id, "STEP: wykonanie zakończone (execute_step_cloud_run)");
        Ok(())
    }

    /// Wykonanie pojedynczego kroku z sesją w DB (start_process_f / finish_process_f).
    async fn execute_step_with_session(
        &self,
        file_id: &str,
        gcs_file_uri: &str,
        step: &ProcessStep,
    ) -> Result<()> {
        // Jeśli brak DB – po prostu wykonujemy krok
        let Some(db) = &self.db else {
            return self.execute_step_cloud_run(file_id, gcs_file_uri, step).await;
        };

        let process_cd = &step.process_cd;
        let file_watcher_id = self.cfg.file_watcher_id.unwrap_or(0);
        let tech_insert_id = self.cfg.tech_insert_id.unwrap_or(0);

        info!(
            %file_id,
            %process_cd,
            %file_watcher_id,
            "STEP DB: wywołuję start_process_f() dla kroku"
        );

        let pid = db
            .init_session(process_cd, file_watcher_id, tech_insert_id)
            .await
            .context("STEP DB: błąd start_process_f() dla kroku")?;

        // Właściwe wykonanie kroku (Cloud Run)
        let result = self
            .execute_step_cloud_run(file_id, gcs_file_uri, step)
            .await;

        let tech_update_id = self
            .cfg
            .tech_update_id
            .or(self.cfg.tech_insert_id)
            .unwrap_or(0);

        let (status_cd, error_msg) = match &result {
            Ok(_) => ("COMPLETED", "".to_string()),
            Err(e) => ("ERROR", e.to_string()),
        };

        if let Err(e) = db
            .end_session(pid, status_cd, &error_msg, tech_update_id)
            .await
        {
            error!(
                error=?e,
                %pid,
                %file_id,
                "STEP DB: błąd finish_process_f() dla kroku"
            );
        }

        result
    }
